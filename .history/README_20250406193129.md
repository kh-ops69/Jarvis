‚∏ª

# Jarvis üß† ‚Äî Agentic AI Assistant with Local + Gemini Hybrid Intelligence

**Jarvis** is a fully local, privacy-first AI assistant that mimics a **Manus-like experience** ‚Äî executing terminal commands, browsing the web, managing your filesystem, and writing code ‚Äî all through autonomous, multi-agent orchestration. Powered by **Llama 3.2 agents** and enhanced with **Gemini browsing**, it ensures minimal data leakage and maximum utility.


---

![Jarvis Banner](./media/jarvis.jpg)

> *Do a deep search of AI startups in Osaka and Tokyo, find at least 5, then save them in `research_japan.txt`.*

> *Can you make a tetris game in C ?*

> *I would like to set up a new project file index as mark2.*

---

## üöÄ Key Features

- **Agentic AI Architecture**: Uses multiple specialized agents for browser tasks, coding, system interaction, and planning.
- **Hybrid Intelligence**: 
  - **Gemini** handles browser and web search queries (more reliable than Selenium + searxng).
  - **Local Ollama Models** (e.g., `llama3.2:1b`) preserve privacy by reducing external API usage.
- **Modular Planning Engine**: Automatically routes tasks to appropriate agents or chains them for complex reasoning.
- **Autonomous Web Navigation**: Conducts research, fills forms, and gathers content from the internet.
- **Terminal Agent**: Execute Linux commands and scripts intelligently.
- **Filesystem Navigator**: Locate, read, write and organize files using natural language.
- **Voice Input Support**: Triggerable speech-to-text system for hands-free control.

---

## üîê Privacy First

Jarvis prioritizes **data privacy**. All code execution and reasoning can be done locally, with only browsing requests optionally sent to **Gemini** for superior performance.

---

## üì¶ Installation

Make sure you have **Python 3.10+**, **ChromeDriver**, and **Docker** installed.

### 1Ô∏è‚É£ Clone and Setup

```bash
git clone https://github.com/kh-ops69/Jarvis.git
cd Jarvis
mv .env.example .env

2Ô∏è‚É£ Create Virtual Environment

python3 -m venv jarvis_env
source jarvis_env/bin/activate
# Windows: jarvis_env\Scripts\activate

3Ô∏è‚É£ Install Dependencies

Auto-install:

./install.sh

Manual:

pip install -r requirements.txt



‚∏ª

üß† Running the Assistant

Option A: Local Model via Ollama (Recommended for Privacy)
	1.	Install Ollama
	2.	Pull a lightweight model:

ollama pull llama3.2:1b

	3.	Update config.ini:

[MAIN]
is_local = True
provider_name = ollama
provider_model = llama3.2:1b
provider_server_address = 127.0.0.1:11434

	4.	Run:

ollama serve
sudo ./start_services.sh
python3 main.py

‚ö†Ô∏è For complex reasoning, use deepseek-r1:14b or better (if your hardware allows).

‚∏ª

Option B: Gemini-Powered Browsing
	‚Ä¢	Gemini is automatically used for browsing if configured.
	‚Ä¢	It improves accuracy over traditional automated browsing (e.g., selenium/searxng).
	‚Ä¢	Queries like ‚ÄúFind latest research papers on AI agents‚Äù will route to Gemini.

‚∏ª

Option C: Remote Model Server
	1.	On your remote server:

ollama pull deepseek-r1:14b
python3 app.py --provider ollama --port 3333

	2.	On your laptop:

[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:14b
provider_server_address = x.x.x.x:3333

Then run:

sudo ./start_services.sh
python3 main.py



‚∏ª

üéôÔ∏è Voice Activation
	1.	In config.ini:

listen = True
agent_name = Friday

	2.	Trigger by saying the agent name aloud, then speak your query.
	3.	End with phrases like ‚Äúdo it‚Äù, ‚Äúplease‚Äù, ‚Äúrun‚Äù, etc.

‚∏ª

üíª Example Commands

Coding / Terminal
	‚Ä¢	Write a snake game in Python
	‚Ä¢	Show all processes using over 1GB RAM
	‚Ä¢	Compile this C file and run it

Web Browsing
	‚Ä¢	Find cheapest RTX 4090 online
	‚Ä¢	Search GitHub for trending AI projects

Filesystem
	‚Ä¢	Find contract.pdf and open it
	‚Ä¢	How much space is left on this disk?

Casual
	‚Ä¢	Who is the president of South Korea?
	‚Ä¢	Should I take creatine before or after a workout?

‚∏ª

üåê Providers Overview

Provider	Local?	Description
ollama	‚úÖ	Run models locally
server	‚úÖ	Use your own server
lm-studio	‚úÖ	Use LM Studio for local inference
openai	‚ùå	GPT-3.5, GPT-4 via OpenAI API
deepseek-api	‚ùå	Use DeepSeek‚Äôs hosted API
huggingface	‚ùå	Hugging Face Inference API

Update config.ini accordingly.

‚∏ª

üß™ Known Issues


`Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path`

This happen if there is a mismatch between your browser and chromedriver version.

You need to navigate to download the latest version:

https://developer.chrome.com/docs/chromedriver/downloads

If you're using Chrome version 115 or newer go to:

https://googlechromelabs.github.io/chrome-for-testing/

And download the chromedriver version matching your OS.


‚∏ª

üîß Issues
	1.	Model Limitations:
The current system uses a smaller LLaMA 3.2 model with approximately 1 billion parameters. While this allows for faster inference, it significantly reduces accuracy and instruction-following ability. It often requires multiple prompts (trial and error) to steer the model in the right direction.
Upgrade to a larger model (‚â•14B parameters) if hardware permits, to improve response quality and reduce prompt iterations.
	2.	Error Handling:
Due to the smaller model, many edge cases throw unexpected errors that cause the agent or the system to fail.
Robust error handling needs to be added throughout the agent‚Äôs workflow.
	3.	Command Execution Inconsistencies:
Commands generated for terminal or file operations sometimes do not execute as expected because of inconsistencies in code generation or lack of context.
More rigorous testing and validation are required, especially when using smaller models, to ensure commands are reliable.
	4.	Missing Step-by-Step Validation:
There is no validation at intermediate steps‚Äîsuch as when the plan is generated, commands are executed, or intermediate outputs are received.
Add checkpoint validations throughout the agent‚Äôs reasoning and execution pipeline.
	5.	Poor Logical Flow & Redundant Code:
The codebase contains redundant files and testing modules, making the overall flow cluttered and confusing.
Refactoring required for better clarity, modularization, and readability.
	6.	Unreliable Speech-to-Text Functionality:
Speech input functionality is present but not thoroughly tested, and may not work as expected in all environments.
	7.	Cross-Platform Compatibility Not Verified:
The system has only been tested on a Mac M1 with 8GB RAM. Code exists for Windows and Linux, but platform-specific compatibility is unverified.
Thorough testing on Windows and Linux environments is necessary.

‚∏ª

